{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dba447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce GTX 1660\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from scipy.special import softmax\n",
    "import sklearn\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "\n",
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) \n",
    "    np.random.seed(seed_value) \n",
    "    torch.manual_seed(seed_value) \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) \n",
    "        torch.backends.cudnn.deterministic = True  \n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all(79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fbd5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence = pd.read_csv('evidence.csv',sep='\\t')\n",
    "fact_checking_train = pd.read_csv('fact_checking_train.csv',sep='\\t')\n",
    "fact_checking_test = pd.read_csv('fact_checking_test.csv',sep='\\t')\n",
    "fact_checking_test['label']=0\n",
    "# label_2_v = {'false':0,'half-true':1,'barely-true':2,'mostly-true':3,'true':4,'pants-fire':5}\n",
    "label_2_v = {'pants-fire':0,'false':1,'barely-true':2,'half-true':3,'mostly-true':4,'true':5}\n",
    "fact_checking_train['label'] = fact_checking_train['label'].map(label_2_v)\n",
    "# Preparing train data\n",
    "train = fact_checking_train[['claim','label']].copy()\n",
    "train.columns = [\"text\", \"labels\"]\n",
    "\n",
    "test = fact_checking_test[['claim','label']].copy()\n",
    "test.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35b141e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257\n"
     ]
    }
   ],
   "source": [
    "temp = fact_checking_train.groupby('author')['label'].value_counts()\n",
    "author = set(fact_checking_train['author'].values)\n",
    "author_label = {}\n",
    "for a in author:\n",
    "    counts = []\n",
    "    for i in range(6):\n",
    "        try:\n",
    "            count = temp[a][i]\n",
    "        except:\n",
    "            count = 0\n",
    "        counts.append(count)\n",
    "    author_label[a] = counts/sum(counts)\n",
    "author_label = pd.DataFrame.from_dict(author_label, orient='index')\n",
    "\n",
    "result = fact_checking_train.join(author_label, on='author')\n",
    "train_x_label = result[[0,1,2,3,4,5]].values\n",
    "result = fact_checking_test.join(author_label, on='author')\n",
    "# 缺失值\n",
    "count = result[0].isna().sum()\n",
    "print (count)\n",
    "result = result.fillna(0)\n",
    "test_x_label = result[[0,1,2,3,4,5]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650d506c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(3, 5) )\n",
    "X = vec.fit_transform(train['text'])\n",
    "model = Ridge(alpha = 1.0)\n",
    "model.fit(X, train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83fd04de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5155555555555555\n",
      "0.5055555555555555\n",
      "0.5111111111111111\n",
      "0.5172222222222222\n",
      "0.5155555555555555\n",
      "0.525\n",
      "0.52\n",
      "0.5083333333333333\n",
      "0.4988888888888889\n",
      "0.5044444444444445\n",
      "Mean f1 score:  0.5121666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=79)\n",
    "err=[]\n",
    "y_pred_tot=[]\n",
    "for train_index, test_index in kf.split(train, train['labels']):\n",
    "    train1_trn, train1_val = train.iloc[train_index], train.iloc[test_index]\n",
    "    # training data\n",
    "    X = vec.fit_transform(train1_trn['text'])\n",
    "    svdT = TruncatedSVD(n_components=128,random_state=2021)\n",
    "    svdT.fit(X)\n",
    "    X = svdT.transform(X)\n",
    "    X = np.hstack([X,train_x_label[train_index]])\n",
    "    # val data \n",
    "    X_test = vec.transform(train1_val['text'])\n",
    "    X_test = svdT.transform(X_test)\n",
    "    X_test = np.hstack([X_test,train_x_label[test_index]])\n",
    "    # test data \n",
    "    test_data = vec.transform(test['text'])\n",
    "    test_data = svdT.transform(test_data)\n",
    "    test_data = np.hstack([test_data,test_x_label])\n",
    "    \n",
    "    \n",
    "#     model = CatBoostClassifier(\n",
    "#         iterations=10000,\n",
    "#         learning_rate=0.07,\n",
    "# #         l2_leaf_reg=50,\n",
    "#         task_type=\"GPU\",\n",
    "#         loss_function=\"MultiClass\",\n",
    "# #         logging_level='Verbose',\n",
    "#         eval_metric='Accuracy'\n",
    "#     )    \n",
    "#     model.fit(X, train1_trn['labels'], eval_set=[(X_test, train1_val['labels'])], early_stopping_rounds=100)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=79).fit(X, train1_trn['labels'])\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(train1_val['labels'], y_pred)\n",
    "    print(acc)\n",
    "    err.append(acc)\n",
    "    raw_outputs = clf.predict_proba(test_data)\n",
    "    y_pred_tot.append(raw_outputs)\n",
    "#     break\n",
    "print(\"Mean f1 score: \",np.mean(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd6241a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    orig_shape = x.shape\n",
    "\n",
    "    if len(x.shape) > 1:\n",
    "        # Matrix\n",
    "        exp_minmax = lambda x: np.exp(x - np.max(x))\n",
    "        denom = lambda x: 1.0 / np.sum(x)\n",
    "        x = np.apply_along_axis(exp_minmax,1,x)\n",
    "        denominator = np.apply_along_axis(denom,1,x) \n",
    "        \n",
    "        if len(denominator.shape) == 1:\n",
    "            denominator = denominator.reshape((denominator.shape[0],1))\n",
    "        \n",
    "        x = x * denominator\n",
    "    else:\n",
    "        # Vector\n",
    "        x_max = np.max(x)\n",
    "        x = x - x_max\n",
    "        numerator = np.exp(x)\n",
    "        denominator =  1.0 / np.sum(numerator)\n",
    "        x = numerator.dot(denominator)\n",
    "    \n",
    "    assert x.shape == orig_shape\n",
    "    return x\n",
    "sum(softmax(y_pred_tot[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dc6cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i == 0:\n",
    "        res = softmax(y_pred_tot[i])/10\n",
    "    else:\n",
    "        res += softmax(y_pred_tot[i])/10\n",
    "res = np.argmax(res, axis=1)\n",
    "sub = pd.read_csv('submission.csv', sep='\\t')\n",
    "sub['label'] = res\n",
    "v_2_label = {0:'pants-fire',1:'false',2:'barely-true',3:'half-true',4:'mostly-true',5:'true'}\n",
    "sub['label'] = sub['label'].map(v_2_label)\n",
    "sub.to_csv('sub_test.csv',index=None,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0209251b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18000</td>\n",
       "      <td>barely-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18001</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18002</td>\n",
       "      <td>barely-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18003</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18004</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>19788</td>\n",
       "      <td>barely-true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>19789</td>\n",
       "      <td>pants-fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>19790</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>19791</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>19792</td>\n",
       "      <td>barely-true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1793 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID        label\n",
       "0     18000  barely-true\n",
       "1     18001        false\n",
       "2     18002  barely-true\n",
       "3     18003        false\n",
       "4     18004        false\n",
       "...     ...          ...\n",
       "1788  19788  barely-true\n",
       "1789  19789   pants-fire\n",
       "1790  19790         true\n",
       "1791  19791        false\n",
       "1792  19792  barely-true\n",
       "\n",
       "[1793 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtest =  pd.read_csv('./sub_test.csv', sep='\\t')\n",
    "subtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3450bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = fact_checking_train.groupby('author')['label'].value_counts()\n",
    "# author = set(fact_checking_train['author'].values)\n",
    "# author_label = {}\n",
    "# for a in author:\n",
    "#     counts = []\n",
    "#     for i in range(6):\n",
    "#         try:\n",
    "#             count = temp[a][i]\n",
    "#         except:\n",
    "#             count = 0\n",
    "#         counts.append(count)\n",
    "#     author_label[a] = counts/sum(counts)\n",
    "# author_label = pd.DataFrame.from_dict(author_label, orient='index')\n",
    "\n",
    "# result = fact_checking_train.join(author_label, on='author')\n",
    "\n",
    "# result = fact_checking_test.join(author_label, on='author')\n",
    "# result = result.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a5224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
